{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe6f73d",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b6a5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (3.13.3) (Python 3.13.3)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"d:/Metode Penelitian/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"enalis/tomatoes-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b004f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_dir = os.path.join(path, \"content\",\"ieee-mbl-cls\",\"train\")\n",
    "print(\"Kategori\",os.listdir(dataset_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f54e854",
   "metadata": {},
   "source": [
    "**Data Preprocessing dan Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    shear_range=0.1,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Generator validation\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Coba cek batch\n",
    "x, y = next(iter(train_gen))\n",
    "print(\"Train batch shape:\", x.shape)\n",
    "print(\"Label batch shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f68aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_gen.samples, \"train images\")\n",
    "print(val_gen.samples, \"validation images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "\n",
    "# for folder in os.listdir(dataset_dir):\n",
    "#     subdir = os.path.join(dataset_dir, folder)\n",
    "#     if os.path.isdir(subdir):\n",
    "#         for file in os.listdir(subdir):\n",
    "#             if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "#                 path = os.path.join(subdir, file)\n",
    "#                 try:\n",
    "#                     img = Image.open(path)\n",
    "#                     if img.mode == 'RGBA':\n",
    "#                         img = img.convert('RGB')\n",
    "#                         img.save(path)\n",
    "#                         print(f\"Converted {file} in {folder} to RGB âœ…\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"âš ï¸ Error on {file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209377a8",
   "metadata": {},
   "source": [
    "**Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e49ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, preprocess_func, generator):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for i, (batch_x, batch_y) in enumerate(generator):\n",
    "        if len(batch_x) == 0:\n",
    "            continue\n",
    "        batch_x = preprocess_func(batch_x)\n",
    "        feat = model.predict(batch_x, verbose=0)\n",
    "        features.append(feat)\n",
    "        labels.append(batch_y)\n",
    "\n",
    "        # hentikan kalau sudah cukup data\n",
    "        if hasattr(generator, 'n') and len(features) * generator.batch_size >= generator.n:\n",
    "            break\n",
    "\n",
    "    if len(features) == 0:\n",
    "        raise ValueError(\"Generator tidak menghasilkan batch apapun!\")\n",
    "\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return features, labels\n",
    "\n",
    "# Membuka layer terakhir untuk fine-tuning\n",
    "for layer in model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, shutil, os\n",
    "\n",
    "cache_dir = os.path.expanduser('~/.keras/models')\n",
    "if os.path.exists(cache_dir):\n",
    "    shutil.rmtree(cache_dir)\n",
    "\n",
    "print(\"âœ… Cache EfficientNet dibersihkan. Jalankan ulang model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f2b9a3",
   "metadata": {},
   "source": [
    "**Transfer Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7691055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2, ResNet50, EfficientNetB0\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficient_preprocess\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "backbones = {\n",
    "    \"MobileNetV2\": (\n",
    "        MobileNetV2(weights='imagenet', include_top=False, pooling='avg', input_shape=(224,224,3)), \n",
    "        mobilenet_preprocess\n",
    "    ),\n",
    "    \"ResNet50\": (\n",
    "        ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(224,224,3)), \n",
    "        resnet_preprocess\n",
    "    )\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, (model, preprocess_func) in backbones.items():\n",
    "    print(f\"\\nðŸ”¹ Ekstraksi fitur menggunakan {name}...\")\n",
    "    X_train, y_train = extract_features(model, preprocess_func, train_gen)\n",
    "    X_val, y_val = extract_features(model, preprocess_func, val_gen)\n",
    "\n",
    "    # Flatten label one-hot ke argmax\n",
    "    y_train = np.argmax(y_train, axis=1)\n",
    "    y_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "    classifiers = {\n",
    "        \"SVM\": SVC(kernel='linear'),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    }\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        print(f\"   ðŸ§  Training {clf_name} untuk {name}...\")\n",
    "        start = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        elapsed = time.time() - start\n",
    "        results.append([name, clf_name, acc, elapsed])\n",
    "        print(f\"   âœ… Akurasi: {acc:.4f} | Waktu: {elapsed:.2f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a51b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_results = pd.DataFrame(results, columns=[\"Backbone\", \"Classifier\", \"Accuracy\", \"Training Time (s)\"])\n",
    "print(\"\\nðŸ“Š Hasil Perbandingan:\")\n",
    "print(df_results.sort_values(by=\"Accuracy\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74518220",
   "metadata": {},
   "source": [
    "**Model Pembanding**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
